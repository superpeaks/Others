{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d59fb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Increase the field size limit (e.g., to 10 MB)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m csv\u001b[38;5;241m.\u001b[39mfield_size_limit(sys\u001b[38;5;241m.\u001b[39mmaxsize)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtsv_to_csv\u001b[39m(input_tsv_file, output_csv_file):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_tsv_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tsv_file:\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "\n",
    "# Increase the field size limit (e.g., to 10 MB)\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "def tsv_to_csv(input_tsv_file, output_csv_file):\n",
    "    with open(input_tsv_file, \"r\", newline='', encoding='utf-8') as tsv_file:\n",
    "        tsv_reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "        \n",
    "        with open(output_csv_file, \"w\", newline='', encoding='utf-8') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerows(tsv_reader)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_tsv_file = \"input_file.tsv\"\n",
    "    output_csv_file = \"output_file.csv\"\n",
    "\n",
    "    tsv_to_csv(input_tsv_file, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65947314",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:/tsv\\\\data.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 78\u001b[0m\n\u001b[0;32m     74\u001b[0m             connection\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# Generate the SQL file\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     \u001b[43mgenerate_sql_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTSV_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSQL_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Import data into PostgreSQL\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     import_to_postgresql()\n",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m, in \u001b[0;36mgenerate_sql_file\u001b[1;34m(tsv_file, sql_file)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_sql_file\u001b[39m(tsv_file, sql_file):\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m tsv_file, \u001b[38;5;28mopen\u001b[39m(sql_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m sql_file:\n\u001b[0;32m     29\u001b[0m         tsv_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(tsv_file, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m         headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(tsv_reader)  \u001b[38;5;66;03m# Get the header row\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:/tsv\\\\data.tsv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "\n",
    "# Define PostgreSQL connection parameters\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"IDMP\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"Rsj\"\n",
    "\n",
    "# Define file paths\n",
    "TSV_FOLDER = \"c:/tsv\"\n",
    "TSV_FILE = os.path.join(TSV_FOLDER, \"data.tsv\")\n",
    "\n",
    "PSQL_FOLDER = \"c:/psql\"\n",
    "SQL_FILE = os.path.join(PSQL_FOLDER, \"output_filename.sql\")\n",
    "\n",
    "# Create the PSQL folder if it doesn't exist\n",
    "if not os.path.exists(PSQL_FOLDER):\n",
    "    os.makedirs(PSQL_FOLDER)\n",
    "\n",
    "# Define the SQL INSERT statement template based on the number of columns in the TSV file\n",
    "INSERT_TEMPLATE = \"INSERT INTO your_table_name (column1, column2, ...) VALUES ({0});\\n\"\n",
    "\n",
    "def generate_sql_file(tsv_file, sql_file):\n",
    "    with open(tsv_file, \"r\", encoding='utf-8') as tsv_file, open(sql_file, \"w\", encoding='utf-8') as sql_file:\n",
    "        tsv_reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "        headers = next(tsv_reader)  # Get the header row\n",
    "\n",
    "        # Format the SQL INSERT statement with column names\n",
    "        insert_statement = INSERT_TEMPLATE.format(\", \".join(headers))\n",
    "\n",
    "        # Write the INSERT statement to the SQL file\n",
    "        sql_file.write(insert_statement)\n",
    "\n",
    "        for row in tsv_reader:\n",
    "            # Create a comma-separated list of values for the current row\n",
    "            values = \", \".join(f\"'{value}'\" for value in row)\n",
    "\n",
    "            # Format the INSERT statement and write it to the SQL file\n",
    "            insert_statement = INSERT_TEMPLATE.format(values)\n",
    "            sql_file.write(insert_statement)\n",
    "\n",
    "    print(f\"SQL file generated: {SQL_FILE}\")\n",
    "\n",
    "def import_to_postgresql():\n",
    "    try:\n",
    "        # Connect to the PostgreSQL database\n",
    "        connection = psycopg2.connect(\n",
    "            host=DB_HOST,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Execute the SQL file using the COPY command to import the TSV data\n",
    "        with open(SQL_FILE, \"r\", encoding='utf-8') as sql_file:\n",
    "            cursor.copy_expert(sql_file.read(), 'your_table_name')\n",
    "\n",
    "        connection.commit()\n",
    "        print(\"Data imported into PostgreSQL successfully!\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(\"Error while importing data to PostgreSQL:\", e)\n",
    "\n",
    "    finally:\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Generate the SQL file\n",
    "    generate_sql_file(TSV_FILE, SQL_FILE)\n",
    "\n",
    "    # Import data into PostgreSQL\n",
    "    import_to_postgresql()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9906f1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while creating table and importing data to PostgreSQL: missing data for column \"genres\"\n",
      "CONTEXT:  COPY title_basics, line 678273: \"tt0701219\ttvEpisode\tSummer of 4'2\"\tSummer of 4'2\"\t0\t1996\t\\N\t30\tAnimation,Comedy\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "def create_table_from_tsv(tsv_file, db_host, db_port, db_name, db_user, db_password, table_name):\n",
    "    try:\n",
    "        # Connect to the PostgreSQL database\n",
    "        connection = psycopg2.connect(\n",
    "            host=db_host,\n",
    "            port=db_port,\n",
    "            database=db_name,\n",
    "            user=db_user,\n",
    "            password=db_password\n",
    "        )\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Read the TSV file and extract the column headers\n",
    "        with open(tsv_file, 'r', encoding='utf-8') as f:\n",
    "            tsv_reader = csv.reader(f, delimiter='\\t')\n",
    "            headers = next(tsv_reader)\n",
    "\n",
    "        # Create the table with column headers and define columns as nullable\n",
    "        columns = \", \".join(f\"{header} TEXT\" for header in headers)\n",
    "        create_table_query = f\"CREATE TABLE {table_name} ({columns});\"\n",
    "        cursor.execute(create_table_query)\n",
    "\n",
    "        # Use the COPY command to load data from the TSV file into the table\n",
    "        with open(tsv_file, 'r', encoding='utf-8') as f:\n",
    "            # Skip the header row\n",
    "            next(f)\n",
    "\n",
    "            # Create an in-memory file-like object to hold the data\n",
    "            data = StringIO(f.read())\n",
    "\n",
    "        # Prepare the rows with NULL values for missing fields\n",
    "        cleaned_data = StringIO()\n",
    "        for line in data:\n",
    "            values = line.strip().split('\\t')\n",
    "            cleaned_values = [value if value != '' else 'NULL' for value in values]\n",
    "            cleaned_data.write('\\t'.join(cleaned_values) + '\\n')\n",
    "\n",
    "        cleaned_data.seek(0)  # Reset the buffer position to the beginning\n",
    "\n",
    "        # Copy the data from the in-memory file-like object into the table\n",
    "        copy_query = f\"COPY {table_name} ({', '.join(headers)}) FROM STDIN DELIMITER E'\\\\t' CSV NULL 'NULL' HEADER;\"\n",
    "        cursor.copy_expert(copy_query, cleaned_data)\n",
    "\n",
    "        # Commit the changes\n",
    "        connection.commit()\n",
    "\n",
    "        print(\"Table created and data imported into PostgreSQL successfully!\")\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Error while creating table and importing data to PostgreSQL:\", e)\n",
    "\n",
    "    finally:\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace these values with your PostgreSQL connection details and TSV file path\n",
    "    db_host = \"localhost\"\n",
    "    db_port = \"5432\"\n",
    "    db_name = \"idmb\"\n",
    "    db_user = \"postgres\"\n",
    "    db_password = \"Rsj\"\n",
    "    tsv_file = \"C:/Users/Rajes/Desktop/PSQL/data.tsv\"\n",
    "    table_name = \"title_basics\"\n",
    "\n",
    "    create_table_from_tsv(tsv_file, db_host, db_port, db_name, db_user, db_password, table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab56260-d1ee-427d-a340-d06f4a7c0ded",
   "metadata": {},
   "source": [
    "# Working Codes\n",
    "\n",
    "**PostgreSQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372abd6-4a3d-4a7d-907d-e35369de2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "# MySQL database details\n",
    "mysql_username = 'root'\n",
    "mysql_password = 'password'\n",
    "mysql_host = 'localhost'\n",
    "mysql_port = '3306'\n",
    "mysql_database = 'gdb041'\n",
    "\n",
    "# PostgreSQL database details\n",
    "postgresql_username = 'pg_database_owner'\n",
    "postgresql_password = 'Rsj'\n",
    "postgresql_host = 'localhost'\n",
    "postgresql_port = '5432'\n",
    "postgresql_database = 'gdb041'\n",
    "\n",
    "# Connect to the MySQL database using SQLAlchemy\n",
    "mysql_url = f\"mysql://{mysql_username}:{mysql_password}@{mysql_host}:{mysql_port}/{mysql_database}\"\n",
    "mysql_engine = create_engine(mysql_url)\n",
    "\n",
    "# Connect to the PostgreSQL database using SQLAlchemy\n",
    "postgresql_url = f\"postgresql://{postgresql_username}:{postgresql_password}@{postgresql_host}:{postgresql_port}/{postgresql_database}\"\n",
    "postgresql_engine = create_engine(postgresql_url)\n",
    "\n",
    "# Table to be migrated\n",
    "table_name = 'dim_customer'\n",
    "\n",
    "# Export data from MySQL table to pandas DataFrame\n",
    "query = f\"SELECT * FROM {table_name};\"\n",
    "df = pd.read_sql(query, mysql_engine)\n",
    "\n",
    "# Create the table in PostgreSQL (using pandas)\n",
    "df.to_sql(table_name, postgresql_engine, if_exists='replace', index=False, method='multi')\n",
    "\n",
    "# Optionally, you may need to handle data transformations, indexes, and constraints\n",
    "# between MySQL and PostgreSQL databases based on the specific schema of the table.\n",
    "\n",
    "print(f\"Migration of table {table_name} from MySQL to PostgreSQL completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81245d8-8ebd-43a4-8c7f-6f6ba31fda92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "TSV_FOLDER = \"c:/tsv\"\n",
    "TSV_FILE = os.path.join(TSV_FOLDER, \"uncompressed_filename.tsv\")\n",
    "\n",
    "PSQL_FOLDER = \"c:/psql\"\n",
    "SQL_FILE = os.path.join(PSQL_FOLDER, \"output_filename.sql\")\n",
    "\n",
    "# Create the PSQL folder if it doesn't exist\n",
    "if not os.path.exists(PSQL_FOLDER):\n",
    "    os.makedirs(PSQL_FOLDER)\n",
    "\n",
    "# Define the SQL INSERT statement template based on the number of columns in the TSV file\n",
    "INSERT_TEMPLATE = \"name_basics (column1, column2, ...) VALUES ({0});\\n\"\n",
    "\n",
    "with open(TSV_FILE, \"r\", encoding='utf-8') as tsv_file, open(SQL_FILE, \"w\", encoding='utf-8') as sql_file:\n",
    "    tsv_reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    next(tsv_reader)  # Skip header if present\n",
    "\n",
    "    for row in tsv_reader:\n",
    "        # Create a comma-separated list of values for the current row\n",
    "        values = \", \".join(f\"'{value}'\" for value in row)\n",
    "\n",
    "        # Format the INSERT statement and write it to the SQL file\n",
    "        insert_statement = INSERT_TEMPLATE.format(values)\n",
    "        sql_file.write(insert_statement)\n",
    "\n",
    "print(f\"SQL file generated: {SQL_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021de23-f530-4dbd-853f-3ca1fc35f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "\n",
    "# Define PostgreSQL connection parameters\n",
    "DB_HOST = \"your_host\"\n",
    "DB_PORT = \"your_port\"\n",
    "DB_NAME = \"your_database_name\"\n",
    "DB_USER = \"your_username\"\n",
    "DB_PASSWORD = \"your_password\"\n",
    "\n",
    "# Define file paths\n",
    "TSV_FOLDER = \"c:/tsv\"\n",
    "TSV_FILE = os.path.join(TSV_FOLDER, \"uncompressed_filename.tsv\")\n",
    "\n",
    "PSQL_FOLDER = \"c:/psql\"\n",
    "SQL_FILE = os.path.join(PSQL_FOLDER, \"output_filename.sql\")\n",
    "\n",
    "# Create the PSQL folder if it doesn't exist\n",
    "if not os.path.exists(PSQL_FOLDER):\n",
    "    os.makedirs(PSQL_FOLDER)\n",
    "\n",
    "# Define the SQL INSERT statement template based on the number of columns in the TSV file\n",
    "INSERT_TEMPLATE = \"INSERT INTO your_table_name (column1, column2, ...) VALUES ({0});\\n\"\n",
    "\n",
    "def generate_sql_file(tsv_file, sql_file):\n",
    "    with open(tsv_file, \"r\", encoding='utf-8') as tsv_file, open(sql_file, \"w\", encoding='utf-8') as sql_file:\n",
    "        tsv_reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "        headers = next(tsv_reader)  # Get the header row\n",
    "\n",
    "        # Format the SQL INSERT statement with column names\n",
    "        insert_statement = INSERT_TEMPLATE.format(\", \".join(headers))\n",
    "\n",
    "        # Write the INSERT statement to the SQL file\n",
    "        sql_file.write(insert_statement)\n",
    "\n",
    "        for row in tsv_reader:\n",
    "            # Create a comma-separated list of values for the current row\n",
    "            values = \", \".join(f\"'{value}'\" for value in row)\n",
    "\n",
    "            # Format the INSERT statement and write it to the SQL file\n",
    "            insert_statement = INSERT_TEMPLATE.format(values)\n",
    "            sql_file.write(insert_statement)\n",
    "\n",
    "    print(f\"SQL file generated: {SQL_FILE}\")\n",
    "\n",
    "def import_to_postgresql():\n",
    "    try:\n",
    "        # Connect to the PostgreSQL database\n",
    "        connection = psycopg2.connect(\n",
    "            host=DB_HOST,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Execute the SQL file using the COPY command to import the TSV data\n",
    "        with open(SQL_FILE, \"r\", encoding='utf-8') as sql_file:\n",
    "            cursor.copy_expert(sql_file.read(), 'your_table_name')\n",
    "\n",
    "        connection.commit()\n",
    "        print(\"Data imported into PostgreSQL successfully!\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(\"Error while importing data to PostgreSQL:\", e)\n",
    "\n",
    "    finally:\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Generate the SQL file\n",
    "    generate_sql_file(TSV_FILE, SQL_FILE)\n",
    "\n",
    "    # Import data into PostgreSQL\n",
    "    import_to_postgresql()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
